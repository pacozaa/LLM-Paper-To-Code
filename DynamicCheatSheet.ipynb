{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVXC7JqO9TfwVhd0SKgbfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pacozaa/LLM-Paper-To-Code/blob/main/DynamicCheatSheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "TxwFhr7Y17v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e462408-1dd3-4e95-88b4-28c1587708f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-ai-inference in /usr/local/lib/python3.12/dist-packages (1.0.0b9)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (1.36.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Install Dependency\n",
        "!pip install azure-ai-inference datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "\n",
        "import re\n",
        "import json"
      ],
      "metadata": {
        "id": "4dzK7-vj-EiY"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai/gpt-4.1\"#openai/gpt-4.1 , phi-4\n",
        "temperature=1.0\n",
        "top_p=1.0\n",
        "github_token=userdata.get('GITHUB_TOKEN') #GitHub Token"
      ],
      "metadata": {
        "id": "B-C5k0ZaHR4o"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://models.github.ai/inference\"\n",
        "\n",
        "token = github_token\n",
        "\n",
        "client = ChatCompletionsClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(token),\n",
        ")"
      ],
      "metadata": {
        "id": "kA0dTueT-Ke3"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "generator_template=\"\"\"\n",
        "# GENERATOR (PROBLEM SOLVER)\n",
        "\n",
        "Instruction: You are an expert problem-solving assistant tasked with analyzing and solving various questions using a combination of your expertise and provided reference materials. Each task will include:\n",
        "1. A specific question or problem to solve\n",
        "2. A cheatsheet containing relevant strategies, patterns, and examples from similar problems\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ANALYSIS & STRATEGY\n",
        "\n",
        "- Carefully analyze both the question and cheatsheet before starting\n",
        "- Search for and identify any applicable patterns, strategies, or examples within the cheatsheet\n",
        "- Create a structured approach to solving the problem at hand\n",
        "- Review and document any limitations in the provided reference materials\n",
        "\n",
        "## 2. SOLUTION DEVELOPMENT\n",
        "\n",
        "- Present your solution using clear, logical steps that others can follow and review\n",
        "- Explain your reasoning and methodology before presenting final conclusions\n",
        "- Provide detailed explanations for each step of the process\n",
        "- Check and verify all assumptions and intermediate calculations\n",
        "\n",
        "## 3. FINAL ANSWER FORMAT\n",
        "\n",
        "Start answering with `## Reasoning steps:` and end with\n",
        "\n",
        "## Final answer:\n",
        "```json\n",
        "\n",
        "````\n",
        "\n",
        "N.B. Make sure that the final answer is properly wrapped inside the ```json ``` block.\n",
        "\n",
        "\n",
        "Example:\n",
        "Puzzle: There are 2 houses, numbered 1 to 2 from left to right.\n",
        "Each house is occupied by a different person.\n",
        "Each house has a unique attribute for each of the following characteristics:\n",
        "- Each person has a unique name: **Arnold, Eric**\n",
        "- People own unique car models: **ford f150, tesla model 3**\n",
        "- The people keep unique animals: **cat, horse**\n",
        "\n",
        "**Clues**:\n",
        "1. Eric is directly left of the person who owns a Tesla Model 3.\n",
        "2. The person who keeps horses is in the first house.\n",
        "\n",
        "Answer:\n",
        "## Reasoning steps:\n",
        "\n",
        "From Clue 1, we know that Eric is to the left of someone, so he must be the owner of House 1 because House 2 is the rightmost house.\n",
        "Additionally, we know that the person in House 2 must be Arnold, and he owns a Tesla Model 3. Thus, Eric owns a Ford F150.\n",
        "From Clue 2, we know that Eric keeps horses in House 1, which means the other house must keep cats. Finally, we arrive at the unique solution to this puzzle.\n",
        "The solution is presented in table format:\n",
        "\n",
        "## Final answer:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"header\":[\n",
        "      \"Houses\",\n",
        "      \"Name\",\n",
        "      \"CarModel\",\n",
        "      \"Animal\"\n",
        "   ],\n",
        "   \"rows\":[\n",
        "      [\n",
        "         \"1\",\n",
        "         \"Eric\",\n",
        "         \"ford f150\",\n",
        "         \"horse\"\n",
        "      ],\n",
        "      [\n",
        "         \"2\",\n",
        "         \"Arnold\",\n",
        "         \"tesla model 3\",\n",
        "         \"cat\"\n",
        "      ]\n",
        "   ]\n",
        "}\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "CHEATSHEET:\n",
        "'''\n",
        "[[CHEATSHEET]]\n",
        "'''\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "Now it is time to solve the following question.\n",
        "\n",
        "CURRENT INPUT:\n",
        "'''\n",
        "[[QUESTION]]\n",
        "'''\n",
        "\"\"\"\n",
        "cheatsheet_template=\"\"\"\n",
        "# CHEATSHEET REFRENCE CURATOR\n",
        "\n",
        "#### 1. Purpose and Goals\n",
        "As the Cheatsheet Curator, you are tasked with creating a continuously evolving reference designed to help solve a wide variety of tasks, including algorithmic challenges, debugging, creative writing, and more. The cheatsheet's purpose is to consolidate verified solutions, reusable strategies, and critical insights into a single, well-structured resource.\n",
        "\n",
        "- The cheatsheet should include quick, accurate, reliable, and practical solutions to a range of technical and creative challenges.\n",
        "- After seeing each input, you should improve the content of the cheatsheet, synthesizing lessons, insights, tricks, and errors learned from past problems and adapting to new challenges.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Core Responsibilities\n",
        "As the Cheatsheet Curator, you should:\n",
        "   - Curate and preserve knolwedge: Select and document only the most relevant, most useful, and most actionable solutions and strategies, while preserving old content of the cheatsheet.\n",
        "   - Maintain accuracy: Ensure that all entries in the cheatsheet are accurate, clear, and well-contextualized.\n",
        "   - Refine and update content: Continuously update and improve the content of the cheatsheet by incorporating new insights and solutions, removing repetitions or trivial information, and adding efficient solutions.\n",
        "   - Ensure practicality and comprehensiveness: Provide critical and informative examples, as well as efficient code snippets and actionable guidelines.\n",
        "\n",
        "Before updating the cheatsheet, however, you should first assess the correctness of the provided solution and strategically incorporate code blocks, insights, and solutions into the new cheatsheet. Always aim to preserve and keep correct, useful, and illustrative solutions and strategies for future cheatsheets.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Principles and Best Practices\n",
        "1. Accuracy and Relevance:\n",
        "   - Only include solutions and strategies that have been tested and proven effective.\n",
        "   - Clearly state any assumptions, limitations, or dependencies (e.g., specific Python libraries or solution hacks).\n",
        "   - For computational problems, encourage Python usage for more accurate calculations.\n",
        "\n",
        "2. Iterative Refinement:\n",
        "   - Continuously improve the cheatsheet by synthesizing both old and new solutions, refining explanations, and removing redundancies.\n",
        "   - Rather than deleting old content and writing new content each time, consider ways to maintain table content and synthesize information from multiple solutions.\n",
        "   - After solving a new problem, document any reusable codes, algorithms, strategies, edge cases, or optimization techniques.\n",
        "\n",
        "3. Clarity and Usability:\n",
        "   - Write concise, actioanble, well-structured entries.\n",
        "   - Focus on key insights or strategies that make solutions correct and effective.\n",
        "\n",
        "4. Reusability:\n",
        "   - Provide clear solutions, pseudocodes, and meta strategies that are easily adaptable to different contexts.\n",
        "   - Avoid trivial content; focus on non-obvious, critical solution details and approaches.\n",
        "   - Make sure to add as many examples as you can in the cheatsheet.\n",
        "   - Any useful, efficient, generalizable, and illustrative solutions to the previous problems should be included in the cheatsheet.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. Cheatsheet Structure\n",
        "The cheatsheet can be divided into the following sections:\n",
        "\n",
        "1. Solutions, Implementation Patterns, and Code Snippets:\n",
        "   - Document reusable code snippets, algorithms, and solution templates.\n",
        "   - Include descriptions, annotated examples, and potential pitfalls, albeit succinctly.\n",
        "\n",
        "2. [OPTIONAL] Edge Cases and Validation Traps:\n",
        "   - Catalog scenarios that commonly cause errors or unexpected behavior.\n",
        "   - Provide checks, validations, or alternative approaches to handle them.\n",
        "\n",
        "3. General Meta-Reasoning Strategies:\n",
        "   - Describe high-level problem-solving frameworks and heuristics (e.g., use Python to solve heuristic problems; in bipartite graphs, max matching = min vertex cover, etc.)\n",
        "   - Provide concrete yet succinct step-by-step guides for tackling complex problems.\n",
        "\n",
        "4. Implement a Usage Counter\n",
        "   - Each entry must include a usage count: Increase the count every time a strategy is successfully used in problem-solving.\n",
        "   - Use the count to prioritize frequently used solutions over rarely applied ones.\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. Formatting Guidelines\n",
        "Use the following structure for each memory item:\n",
        "\n",
        "```\n",
        "## Memory Item 1\n",
        "** Count:  [Number of times this strategy has been used to solve a problem.]\n",
        "\n",
        "### Description\n",
        "[Briefly describe the problem context, purpose, and key aspects of the solution.] (Refence: Q1, Q2, Q6, etc.)\n",
        "\n",
        "### Example\n",
        "[Provide a well-documented code snippet, worked-out solution, or efficient strategy.]\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Memory Item 2\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "[...]\n",
        "\n",
        "## Memory Item N\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "\n",
        "- Tagging: Use references like `(Q14)` or `(Q22)` to link entries to their originating contexts.\n",
        "- Grouping: Organize entries into logical sections and subsections.\n",
        "- Prioritizing: incorporate efficient algorithmic solutions, tricks, and strategies into the cheatsheet.\n",
        "- Diversity: Have as many useful and relevant memory items as possible to guide the model to tackle future questions.\n",
        "\n",
        "N.B. Keep in mind that once the cheatsheet is updated, any previous content not directly included will be lost and cannot be retrieved. Therefore, make sure to explicitly copy any (or all) relevant information from the previous cheatsheet to the new cheatsheet!!!\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. Cheatsheet Template\n",
        "Use the following format for creating and updating the cheatsheet:\n",
        "\n",
        "NEW CHEATSHEET:\n",
        "```\n",
        "<cheatsheet>\n",
        "\n",
        "## Version: [Version Number]\n",
        "\n",
        "SOLUTIONS, IMPLEMENTATION PATTERNS, AND CODE SNIPPETS\n",
        "## Memory Item 1\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "## Memory Item 2\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "GENERAL META-REASONING STRATEGIES\n",
        "## Memory Item N\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "</cheatsheet>\n",
        "```\n",
        "\n",
        "N.B. Make sure that all information related to the cheatsheet is wrapped inside the <cheatsheet> block. The cheatsheet can be as long as circa 2000-2500 words.\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## PREVIOUS CHEATSHEET\n",
        "\n",
        "[[PREVIOUS_CHEATSHEET]]\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## CURRENT INPUT\n",
        "\n",
        "[[QUESTION]]\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## MODEL ANSWER TO THE CURRENT INPUT\n",
        "\n",
        "[[MODEL_ANSWER]]\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "OWL_k6En_BFo"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_generator_prompt(input_txt, generator_cheatsheet_content):\n",
        "    return generator_template.replace(\"[[QUESTION]]\", input_txt).replace(\"[[CHEATSHEET]]\", generator_cheatsheet_content)\n",
        "\n",
        "def get_curator_prompt(input_txt, generator_output, current_cheatsheet):\n",
        "    return cheatsheet_template.replace(\"[[QUESTION]]\", input_txt).replace(\"[[MODEL_ANSWER]]\", generator_output).replace(\"[[PREVIOUS_CHEATSHEET]]\", current_cheatsheet)\n",
        "\n",
        "def llm_generator(input, cheatsheet):\n",
        "    generate_messages = [\n",
        "        UserMessage(get_generator_prompt(input, cheatsheet))\n",
        "    ]\n",
        "    response = client.complete(\n",
        "        messages=generate_messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        model=model_name,\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer\n",
        "\n",
        "def llm_curator(input, output, cheatsheet):\n",
        "    curator_messages = [\n",
        "        UserMessage(get_curator_prompt(input, output, cheatsheet))\n",
        "    ]\n",
        "    response = client.complete(\n",
        "        messages=curator_messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        model=model_name,\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer"
      ],
      "metadata": {
        "id": "sedLEgBl_HRr"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This file contains the functions to extract the final answer, cheatsheet and solution evaluation from model responses.\n",
        "\n",
        "The functions are:\n",
        "* extract_answer(response: str) -> str: Extracts the final answer from the model response.\n",
        "* extract_cheatsheet(response: str, old_cheatsheet: str) -> str: Extracts the cheatsheet from the model response.\n",
        "* extract_solution(response: str, header: str = \"SOLUTION EVALUATION:\", error_message : str = \"No solution evaluation found\") -> str: Extracts the solution evaluation from the model response.\n",
        "\n",
        "Additional functions can be added as needed.\n",
        "\"\"\"\n",
        "\n",
        "def extract_answer(\n",
        "    response: str,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Extracts the final answer from the model response.\n",
        "\n",
        "    Arguments:\n",
        "        response : str : The response from the model.\n",
        "\n",
        "    Returns:\n",
        "        str : The extracted final answer (if not found, returns \"No final answer found\").\n",
        "    \"\"\"\n",
        "    if \"<answer>\" in response:\n",
        "        # <answer> (content) </answer>\n",
        "        try:\n",
        "            txt = response.split(\"<answer>\")[-1].strip()\n",
        "            txt = txt.split(\"</answer>\")[0].strip()\n",
        "            return txt\n",
        "        except:\n",
        "            return \"No final answer found\"\n",
        "    else:\n",
        "        if not(\"FINAL ANSWER\" in response):\n",
        "            return \"No final answer found\"\n",
        "        try:\n",
        "            response = response.split(\"FINAL ANSWER\")[-1].strip()\n",
        "            if response[0] == \":\":\n",
        "                response = response[1:].strip()\n",
        "\n",
        "            # First decide whether to split by \"```\" or \"'''\" based on the presence of \"```\" or \"'''\"\n",
        "            idx_1 = response.find(\"'''\")\n",
        "            idx_2 = response.find(\"```\")\n",
        "            if min(idx_1, idx_2) != -1:\n",
        "                if idx_1 < idx_2:\n",
        "                    response = response.split(\"'''\")[1].strip()\n",
        "                else:\n",
        "                    response = response.split(\"```\")[1].strip()\n",
        "            else:\n",
        "                if idx_1 == -1:\n",
        "                    response = response.split(\"```\")[1].strip()\n",
        "                else:\n",
        "                    response = response.split(\"'''\")[1].strip()\n",
        "\n",
        "            # Special case for P3-Test task: If the first line contains \"python\" then remove it\n",
        "            if response.split(\"\\n\")[0].strip().lower() == \"python\":\n",
        "                response = \"\\n\".join(response.split(\"\\n\")[1:]).strip()\n",
        "            return response\n",
        "        except:\n",
        "            return \"No final answer found\"\n",
        "\n",
        "\n",
        "def extract_cheatsheet(\n",
        "    response: str,\n",
        "    old_cheatsheet: str,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Extracts the cheatsheet from the model response.\n",
        "\n",
        "    Arguments:\n",
        "        response : str : The response from the model.\n",
        "        old_cheatsheet : str : The old cheatsheet to return if the new one is not found.\n",
        "\n",
        "    Returns:\n",
        "        str : The extracted cheatsheet (if not found, returns the old cheatsheet).\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "    # <cheatsheet> (content) </cheatsheet>\n",
        "    if \"<cheatsheet>\" in response:\n",
        "        try:\n",
        "            txt = response.split(\"<cheatsheet>\")[1].strip()\n",
        "            txt = txt.split(\"</cheatsheet>\")[0].strip()\n",
        "            return txt\n",
        "        except:\n",
        "            return old_cheatsheet\n",
        "    else:\n",
        "        return old_cheatsheet\n",
        "\n",
        "\n",
        "def extract_solution(\n",
        "    response: str,\n",
        "    header: str = \"SOLUTION EVALUATION:\",\n",
        "    error_message : str = \"No solution evaluation found\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Extracts the solution evaluation from the model response.\n",
        "\n",
        "    Arguments:\n",
        "        response : str : The response from the model.\n",
        "        header : str : The header to search for the solution evaluation.\n",
        "        error_message : str : The error message to return if the solution evaluation is not found.\n",
        "\n",
        "    Returns:\n",
        "        str : The extracted solution evaluation (if not found, returns the error message).\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "    try:\n",
        "        txt = response.split(header)[1]\n",
        "        try:\n",
        "            txt = txt.split(\"'''\")[1].strip()\n",
        "        except:\n",
        "            return txt.strip()\n",
        "    except:\n",
        "        return response\n",
        "        # return error_message\n",
        "    return txt\n"
      ],
      "metadata": {
        "id": "mX0KaETYWPSF"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "def extract_final_answer_regex(answer):\n",
        "    match = re.search(r'## Final answer:\\s*(.*)', answer, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "def extract_json_from_string(input_string):\n",
        "    \"\"\"\n",
        "    Extract JSON from a string that contains ```json``` code blocks.\n",
        "\n",
        "    Args:\n",
        "        input_string (str): Input string that may contain JSON code blocks\n",
        "\n",
        "    Returns:\n",
        "        list: List of parsed JSON objects/dictionaries, or empty list if none found\n",
        "    \"\"\"\n",
        "    # Regular expression pattern to match JSON code blocks\n",
        "    pattern = r'```json\\n(.*?)\\n```'\n",
        "\n",
        "    # Find all matches in the input string\n",
        "    matches = re.findall(pattern, input_string, re.DOTALL)\n",
        "\n",
        "    json_objects = []\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            # Parse the JSON string into a Python object\n",
        "            json_obj = json.loads(match.strip())\n",
        "            json_objects.append(json_obj)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing JSON: {e}\")\n",
        "            print(f\"Problematic JSON string: {match}\")\n",
        "            continue\n",
        "\n",
        "    return json_objects\n",
        "\n",
        "\n",
        "def find_name_column_index(answer):\n",
        "    \"\"\"Helper function to find the name column index in the header\"\"\"\n",
        "    if 'header' in answer:\n",
        "        try:\n",
        "            return answer['header'].index('name')\n",
        "        except (ValueError, IndexError):\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def normalize_answer(answer, for_comparison=False):\n",
        "    \"\"\"\n",
        "    Unified function to normalize answers for either counting or comparison.\n",
        "\n",
        "    Args:\n",
        "        answer: The answer to normalize\n",
        "        for_comparison: If True, returns normalized rows for comparison.\n",
        "                       If False, returns JSON string for counting duplicates.\n",
        "    \"\"\"\n",
        "    if isinstance(answer, dict) and 'rows' in answer:\n",
        "        name_idx = find_name_column_index(answer)\n",
        "\n",
        "        if for_comparison:\n",
        "            # For comparison: normalize all values and sort rows\n",
        "            normalized_rows = []\n",
        "            for row in answer['rows']:\n",
        "                if name_idx is not None:\n",
        "                    # Use the found name column index\n",
        "                    normalized_row = []\n",
        "                    for i, value in enumerate(row):\n",
        "                        normalized_row.append(str(value).replace(\" \", \"\").lower())\n",
        "                    normalized_rows.append(tuple(normalized_row))\n",
        "                else:\n",
        "                    # Fallback: normalize all values\n",
        "                    normalized_rows.append(tuple(str(val).replace(\" \", \"\").lower() for val in row))\n",
        "\n",
        "            # Sort rows by name for consistent comparison\n",
        "            normalized_rows.sort()\n",
        "            return normalized_rows\n",
        "        else:\n",
        "            # For counting: create dictionary keyed by name\n",
        "            rows_by_name = {}\n",
        "            for row in answer['rows']:\n",
        "                if name_idx is not None:\n",
        "                    name = row[name_idx]\n",
        "                    rows_by_name[name] = tuple(row)  # Convert to tuple for hashability\n",
        "                else:\n",
        "                    # If no name column found, use second column (common pattern) or whole row\n",
        "                    if len(row) > 1:\n",
        "                        rows_by_name[row[1]] = tuple(row)\n",
        "                    else:\n",
        "                        rows_by_name[str(row)] = tuple(row)\n",
        "            return json.dumps(rows_by_name, sort_keys=True)\n",
        "    else:\n",
        "        if for_comparison:\n",
        "            return str(answer).replace(\" \", \"\").lower()\n",
        "        else:\n",
        "            return str(answer)\n"
      ],
      "metadata": {
        "id": "l0Q9gmNGGYsT"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Intermediate Value\n",
        "cheatsheet = \"\"\n",
        "cheatsheet_list = [cheatsheet]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SqoqlkwTPdDe"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5d1063c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "aa6c8ef5-a0de-46a9-e485-071ec2bc9dc2"
      },
      "source": [
        "dataset = load_dataset(\"allenai/ZebraLogicBench-private\", \"grid_mode\", split=\"test\")\n",
        "grid_size = \"4*4\"\n",
        "ds_size = 5\n",
        "filtered_dataset = dataset.filter(lambda x: x[\"size\"] == grid_size).select(range(ds_size)).shuffle(seed=42)\n",
        "display(filtered_dataset)\n",
        "# https://huggingface.co/datasets/allenai/ZebraLogicBench-private\n",
        "# Columns: id, size, puzzle, solution"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'size', 'puzzle', 'solution', 'created_at'],\n",
              "    num_rows: 5\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "filtered_dataset[0]['solution']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "lrqihhxIyPdm",
        "outputId": "85b1e456-c52a-4c57-bf52-a889c0b39217"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'header': ['House', 'Name', 'Cigar', 'FavoriteSport', 'Drink'],\n",
              " 'rows': [['1', 'Alice', 'prince', 'soccer', 'water'],\n",
              "  ['2', 'Arnold', 'blue master', 'tennis', 'coffee'],\n",
              "  ['3', 'Eric', 'dunhill', 'basketball', 'tea'],\n",
              "  ['4', 'Peter', 'pall mall', 'swimming', 'milk']]}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ade07e71",
        "outputId": "64df3b43-f3f7-4562-9c15-91b2cdc25fe9"
      },
      "source": [
        "is_correct_list = []\n",
        "\n",
        "\n",
        "# Get total number of items for progress tracking\n",
        "total_items = len(filtered_dataset)\n",
        "print(f\"Starting processing of {total_items} items...\")\n",
        "\n",
        "for index, item in enumerate(filtered_dataset):\n",
        "    # Calculate progress percentage\n",
        "    progress = (index + 1) / total_items * 100\n",
        "    print(f\"\\n--- Processing item {index + 1}/{total_items} ({progress:.1f}%) ---\")\n",
        "\n",
        "    puzzle_id = item[\"id\"]\n",
        "    puzzle_input = item[\"puzzle\"]\n",
        "\n",
        "    solution = item[\"solution\"]\n",
        "    solution_normalized = normalize_answer(solution, for_comparison=True)\n",
        "\n",
        "    generator_output = llm_generator(puzzle_input, cheatsheet)\n",
        "    generator_output_extracted = extract_final_answer_regex(generator_output)\n",
        "\n",
        "    if generator_output_extracted is None:\n",
        "        print(f\"‚ùå Warning: Could not extract answer from sample {puzzle_id} (Index: {index})\")\n",
        "        is_correct_list.append({\n",
        "            \"id\": puzzle_id,\n",
        "            \"is_correct\": False,\n",
        "            \"is_extracted\": False,\n",
        "            \"index\": index,\n",
        "            \"generator_output\":generator_output\n",
        "        })\n",
        "    else:\n",
        "        # print(f\"‚úÖ Extracted answer: {generator_output_extracted}\")\n",
        "        clean_generator_output_extracted = generator_output_extracted.lower().replace(\" \", \"\")\n",
        "        json_object_generator_output_extracted = extract_json_from_string(clean_generator_output_extracted)\n",
        "\n",
        "        answer_normalized = normalize_answer(json_object_generator_output_extracted[0], for_comparison=True)\n",
        "\n",
        "        is_correct = answer_normalized == solution_normalized\n",
        "\n",
        "        # print(f\"solution:{solution}\\nsolution_normalized:{solution_normalized}\\n\")\n",
        "        # print(f\"answer:{json_object_generator_output_extracted}\\nanswer_normalized:{answer_normalized}\")\n",
        "\n",
        "        if is_correct:\n",
        "            print(f\"‚úÖ SUCCESS: The {puzzle_id} answer is correct!\")\n",
        "            is_correct_list.append({\n",
        "                \"id\": puzzle_id,\n",
        "                \"is_correct\": True,\n",
        "                \"is_extracted\": True,\n",
        "                \"index\": index,\n",
        "                \"generator_output\":generator_output,\n",
        "                \"answer_normalized\":answer_normalized,\n",
        "                \"solution_normalized\":solution_normalized\n",
        "            })\n",
        "        else:\n",
        "            print(f\"‚ùå The {puzzle_id} answer does NOT match the correct answer\")\n",
        "            is_correct_list.append({\n",
        "                \"id\": puzzle_id,\n",
        "                \"is_correct\": False,\n",
        "                \"is_extracted\": True,\n",
        "                \"index\": index,\n",
        "                \"generator_output\":generator_output,\n",
        "                \"answer_normalized\":answer_normalized,\n",
        "                \"solution_normalized\":solution_normalized\n",
        "            })\n",
        "\n",
        "        cheatsheet_output = llm_curator(puzzle_input, generator_output, cheatsheet)\n",
        "        new_cheatsheet = extract_cheatsheet(cheatsheet_output, cheatsheet)\n",
        "        cheatsheet = new_cheatsheet\n",
        "        cheatsheet_list.append(new_cheatsheet)\n",
        "    print(f\"‚úÖ Processed item: {item['id']} (Index: {index})\")\n",
        "\n",
        "    # Optional: Add a break here for testing with a smaller subset\n",
        "    # if index >= 4:  # Test with first 5 items\n",
        "    #     break\n",
        "\n",
        "# Calculate final statistics\n",
        "correct_count = sum(1 for item in is_correct_list if item[\"is_correct\"])\n",
        "accuracy = correct_count / len(is_correct_list) * 100 if is_correct_list else 0\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"‚úÖ Iteration complete! Processed {len(is_correct_list)} items\")\n",
        "print(f\"üìä Results: {correct_count}/{len(is_correct_list)} correct ({accuracy:.1f}% accuracy)\")\n",
        "print(f\"{'='*50}\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing of 5 items...\n",
            "\n",
            "--- Processing item 1/5 (20.0%) ---\n",
            "‚ùå The lgp-test-4x4-13 answer does NOT match the correct answer\n",
            "‚úÖ Processed item: lgp-test-4x4-13 (Index: 0)\n",
            "\n",
            "--- Processing item 2/5 (40.0%) ---\n",
            "‚ùå The lgp-test-4x4-21 answer does NOT match the correct answer\n",
            "‚úÖ Processed item: lgp-test-4x4-21 (Index: 1)\n",
            "\n",
            "--- Processing item 3/5 (60.0%) ---\n",
            "‚úÖ SUCCESS: The lgp-test-4x4-16 answer is correct!\n",
            "‚úÖ Processed item: lgp-test-4x4-16 (Index: 2)\n",
            "\n",
            "--- Processing item 4/5 (80.0%) ---\n",
            "‚úÖ SUCCESS: The lgp-test-4x4-3 answer is correct!\n",
            "‚úÖ Processed item: lgp-test-4x4-3 (Index: 3)\n",
            "\n",
            "--- Processing item 5/5 (100.0%) ---\n",
            "‚úÖ SUCCESS: The lgp-test-4x4-27 answer is correct!\n",
            "‚úÖ Processed item: lgp-test-4x4-27 (Index: 4)\n",
            "\n",
            "==================================================\n",
            "‚úÖ Iteration complete! Processed 5 items\n",
            "üìä Results: 3/5 correct (60.0% accuracy)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# is_correct_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NYw2z5u2Ic5",
        "outputId": "08ee1ea1-7d4e-4083-afda-ce78ed20f2f2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'lgp-test-4x4-13',\n",
              " 'is_correct': False,\n",
              " 'is_extracted': True,\n",
              " 'index': 0,\n",
              " 'generator_output': '## Reasoning steps:\\n\\nLet\\'s carefully analyze the clues and map out the problem systematically, recording intermediate deductions.\\n\\n### 1. Entities\\n- Houses: 1, 2, 3, 4\\n- Names: Alice, Peter, Arnold, Eric\\n- Cigars: prince, dunhill, blue master, pall mall\\n- Sports: swimming, basketball, soccer, tennis\\n- Drinks: coffee, water, milk, tea\\n\\n### 2. Clues Review & Initial Placements\\n\\n#### Assign known places directly from clues.\\n\\n- Clue 1: **Peter is in the fourth house.**  \\n  ‚áí House 4: Peter\\n\\n- Clue 8: **The person who loves basketball is in the third house.**  \\n  ‚áí House 3: Basketball\\n\\n- Clue 4: **The person who loves basketball is Eric.**  \\n  ‚áí House 3: Eric\\n\\nSo:\\n- House 3: Eric, Basketball\\n- House 4: Peter\\n\\n#### Name + Cigar cross referencing\\n\\n- Clue 3: **Arnold is the person who smokes Blue Master.**  \\n  ‚áí Arnold ‚Üî Blue Master\\n\\n- Clue 7: **The coffee drinker is Arnold.**  \\n  ‚áí Arnold ‚Üî Coffee\\n\\n- Clue 5: **The person who loves tennis is the person who smokes Blue Master.**  \\n  ‚áí Tennis ‚Üî Blue Master\\n\\nThus, Arnold is the Blue Master smoker, the coffee drinker, and loves tennis.\\n\\nSo:\\n- Arnold = Blue Master, Coffee, Tennis\\n\\n#### Where is Arnold?\\n\\nHouses 3 and 4 are taken by Eric and Peter, respectively.\\nRemaining: Houses 1, 2.\\n\\n#### Clue 2: **The tea drinker is the person who loves basketball.**\\nBeing that Eric is basketball (already placed in House 3), Eric is also tea drinker.\\n\\nSo:\\n- House 3: Eric, Basketball, Tea\\n\\n#### Clue 10: **Peter is the person partial to Pall Mall.**\\n\\nSo:\\n- House 4: Peter, Pall Mall\\n\\n#### Clue 9: **The Prince smoker is the person who loves soccer.**\\nPrince ‚Üî Soccer\\n\\n#### Clue 6: **There are two houses between the one who only drinks water and Peter.**\\n\\nPeter is in House 4, so:\\n- Water must be in House 1 (since House 1 ‚Üí (houses 2,3) ‚Üí House 4).\\n\\nSo:\\n- House 1: Water\\n\\n#### Cigars left unassigned:\\nHouse 1: ???\\nHouse 2: ???\\n\\n#### Names left unassigned:\\nAlice, Arnold (Alice not yet placed; Arnold must be 1 or 2)\\n\\n#### Sports left unassigned:\\nSwimming, Soccer\\n\\n#### Clue 3 & 5 & 7: Arnold\\'s tuple (Blue Master, Coffee, Tennis) must be placed.\\n\\nHouse 2 is the only space left for Arnold.\\n\\nSo:\\n- House 2: Arnold, Blue Master, Coffee, Tennis\\n\\n#### Update:\\nHouse 1: ???, ???, Water, ???\\nHouse 2: Arnold, Blue Master, Coffee, Tennis\\nHouse 3: Eric, ???, Tea, Basketball\\nHouse 4: Peter, Pall Mall, ???, ???\\n\\nNow, only Alice is left for House 1.\\n\\nSo:\\n- House 1: Alice, ???, Water, ???\\n\\nAlso, only swimming and soccer are left for sports. Out of cigars: prince and dunhill.\\n\\nLet\\'s try to fill in using clue 9.\\n\\n#### Clue 9: Prince smoker = Soccer\\n\\nOnly possible in House 1 or 4, as Houses 2 and 3 have fixed sports.\\n\\nLet\\'s try House 1 first:\\n- Alice, ???, Water, ???\\n\\nIf we set House 1 as Prince and Soccer:\\n- Alice, Prince, Water, Soccer\\n\\nThen House 4 must be:\\n- Peter, Pall Mall, ???, ???\\n\\nFor sports left: swimming. \\n\\nHouse 4: Peter, Pall Mall, ???, Swimming\\n\\nOnly drinks left: Milk\\n\\nHouse 4: Peter, Pall Mall, Milk, Swimming\\n\\nHouse 3: Eric, ???, Tea, Basketball (name/sport/drink complete), only cigar left.\\n\\nCigar options not placed: Dunhill.\\n\\nSo House 3: Eric, Dunhill, Tea, Basketball\\n\\nNow, let\\'s check for consistency with all clues.\\n\\n### 3. Table So Far\\n\\n| House | Name   | Cigar      | Drink  | Sport      |\\n|-------|--------|------------|--------|------------|\\n| 1     | Alice  | Prince     | Water  | Soccer     |\\n| 2     | Arnold | Blue Master| Coffee | Tennis     |\\n| 3     | Eric   | Dunhill    | Tea    | Basketball |\\n| 4     | Peter  | Pall Mall  | Milk   | Swimming   |\\n\\nLet\\'s check every clue for consistency one by one.\\n\\n#### Clue-by-clue consistency\\n\\n1. Peter is in the fourth house. ‚úîÔ∏è (House 4: Peter)\\n2. Tea drinker = basketball lover. ‚úîÔ∏è (Eric, House 3)\\n3. Arnold = blue master smoker. ‚úîÔ∏è (Arnold, House 2)\\n4. Basketball lover = Eric. ‚úîÔ∏è (Eric, House 3)\\n5. Tennis lover = blue master smoker. ‚úîÔ∏è (Arnold, House 2)\\n6. Water drinker is two houses left of Peter. ‚úîÔ∏è (House 1 Alice ‚Äî> House 4 Peter: 1-2-3-4; two houses between 1 and 4)\\n7. Coffee drinker is Arnold. ‚úîÔ∏è (House 2)\\n8. Basketball lover in the third house. ‚úîÔ∏è (House 3)\\n9. Prince smoker = soccer lover. ‚úîÔ∏è (Alice, House 1)\\n10. Peter = Pall Mall. ‚úîÔ∏è (House 4)\\n\\nThus, all clues are satisfied.\\n\\n## Final answer:\\n\\n```json\\n{\\n  \"header\": [\\n    \"House\",\\n    \"Name\",\\n    \"Cigar\",\\n    \"Drink\",\\n    \"Sport\"\\n  ],\\n  \"rows\": [\\n    [ \"1\", \"Alice\",  \"Prince\", \"Water\",    \"Soccer\"      ],\\n    [ \"2\", \"Arnold\", \"Blue Master\", \"Coffee\", \"Tennis\"      ],\\n    [ \"3\", \"Eric\",   \"Dunhill\", \"Tea\",      \"Basketball\"   ],\\n    [ \"4\", \"Peter\",  \"Pall Mall\", \"Milk\",   \"Swimming\"     ]\\n  ]\\n}\\n```',\n",
              " 'answer_normalized': [('1', 'alice', 'prince', 'water', 'soccer'),\n",
              "  ('2', 'arnold', 'bluemaster', 'coffee', 'tennis'),\n",
              "  ('3', 'eric', 'dunhill', 'tea', 'basketball'),\n",
              "  ('4', 'peter', 'pallmall', 'milk', 'swimming')],\n",
              " 'solution_normalized': [('1', 'alice', 'prince', 'soccer', 'water'),\n",
              "  ('2', 'arnold', 'bluemaster', 'tennis', 'coffee'),\n",
              "  ('3', 'eric', 'dunhill', 'basketball', 'tea'),\n",
              "  ('4', 'peter', 'pallmall', 'swimming', 'milk')]}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cheatsheet_list[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "OeOGbS4t-xUL",
        "outputId": "e297103b-22ba-438b-dce6-524e95c86020"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## Version: 2.0\\n\\n---\\n\\nSOLUTIONS, IMPLEMENTATION PATTERNS, AND CODE SNIPPETS\\n\\n---\\n\\n## Memory Item 1\\n**Count: 2**\\n\\n### Description\\n**Logic puzzle (Zebra-type): Tabular setup and permutational search for multi-category assignment.**  \\nEfficiently solve puzzles with multiple entities and mutually exclusive attributes using a table per house. Start with direct assignments from the clues, then use constraint propagation, permutation-based search, and elimination to fill remaining slots. (Reference: Q1, Q2)\\n\\n### Example\\n\\n**Step-by-step pattern:**\\n1. Create a table with each house as a row; columns for each attribute.\\n2. Insert all direct assignments (\"X is Y\", \"X is in house N\").\\n3. Parse clues that relate categories (\"A is B is C in the same house\") and assign those together.\\n4. For clues involving order (\"A is left of B\", \"X is directly to the left of Y\"), use indices.\\n5. For clues like \"N houses between\", calculate allowed pairs (see Memory Item 2).\\n6. Ensure unique assignments across houses.\\n\\n**Python template:**\\n```python\\nfrom itertools import permutations\\nATTRS = {\\n    \"names\": [\"Eric\", \"Peter\", \"Alice\", \"Arnold\"],\\n    \"cars\": [\"tesla model 3\", \"honda civic\", \"toyota camry\", \"ford f150\"],\\n    \"months\": [\"jan\", \"april\", \"sept\", \"feb\"],\\n    \"hobbies\": [\"painting\", \"cooking\", \"gardening\", \"photography\"]\\n}\\n# Generate all possible assignments:\\nfor name in permutations(ATTRS[\\'names\\']):\\n    for car in permutations(ATTRS[\\'cars\\']):\\n        for month in permutations(ATTRS[\\'months\\']):\\n            for hobby in permutations(ATTRS[\\'hobbies\\']):\\n                # Fill all constraints here...\\n                pass\\n```\\n**Usage Tip:** For dense puzzles, list all possible tables, filter via clues, or leverage a constraint programming solver (e.g., python-constraint).\\n\\n---\\n\\n## Memory Item 2\\n**Count: 2**\\n\\n### Description\\n**Clue parsing for \"N houses between\" and positional constraints.**  \\nInterpret clues like \"1 house between A and B\" as index difference 2. For \"directly left of\", difference is 1.  \\nAlso, process clues like \"to the left\" (A is before B in order).\\n\\n### Example\\n\\n- \"X is directly left of Y\": If Y in position p, X is at p‚Äì1.\\n- \"There is one house between X and Y\": If X at p, Y at p+2 or p‚Äì2.\\n- \"X is somewhere to the left of Y\": X\\'s index must be less than Y\\'s index.\\n\\n```python\\ndef positions_with_gap(length, pos, gap):\\n    res = []\\n    if pos - (gap + 1) >= 0:\\n        res.append(pos - (gap + 1))\\n    if pos + (gap + 1) < length:\\n        res.append(pos + (gap + 1))\\n    return res\\n# Example: 4 houses, if Tesla is at 2, gardening must be at 0 or 4\\n```\\n\\n---\\n\\n## Memory Item 3\\n**Count: 2**\\n\\n### Description\\n**Multi-attribute chain assignments and exclusion.**  \\nIf multiple clues link attributes (e.g., \"Arnold owns a Tesla and his birthday is in April\"), bundle and assign all at once. Remove those choices from all other houses.\\n\\n### Example\\n\\nGiven:\\n- Arnold = Tesla Model 3 & April  \\nAssign [Arnold, Tesla Model 3, April] to the same house.\\n\\n---\\n\\n## Memory Item 4\\n**Count: 2**\\n\\n### Description\\n**Consistency check: Validate solution against all constraints.**  \\nOnce the table is filled, methodically check every clue for full compliance. If a clue fails, re-examine ambiguous clues or reassign.\\n\\n### Example\\n\\n- For each clue, e.g. \"Alice is the photography enthusiast\", ensure table[house_with_alice][\\'hobby\\'] == \\'photography\\'.\\n- For clues with order, check indices.\\n\\n**Python check:**\\n```python\\ndef satisfies_all_constraints(table, clues):\\n    for clue in clues:\\n        if not clue(table):\\n            return False\\n    return True\\n```\\n\\n---\\n\\n## Memory Item 5\\n**Count: 2**\\n\\n### Description\\n**Enforcing uniqueness and early pruning in assignment.**  \\nIn assignment-based puzzles, confirm that every category (name, car, month, hobby) features only once per column, eliminating impossible permutations early.\\n\\n### Example\\n\\n- If Alice is assigned to House 1, exclude Alice from other rows and likewise for her car, month, and hobby.\\n\\n---\\n\\n## Memory Item 6\\n**Count: 2**\\n\\n### Description\\n**Python CSP and constraint solver automation for logic puzzles.**  \\nAutomate complex logic puzzles by defining constraints as functions and searching all permutations. Especially powerful for puzzles with 4+ categories.\\n\\n### Example\\n\\n```python\\nfrom constraint import Problem\\nproblem = Problem()\\nhouses = [1, 2, 3, 4]\\nproblem.addVariables(houses, ATTRS[\"names\"])\\n# Define constraint functions such as \"Arnold must have Tesla Model 3 and birthday April\"\\n# problem.addConstraint(...)\\nsolution = problem.getSolutions()\\n```\\n\\n---\\n\\n## Memory Item 7\\n**Count: 2**\\n\\n### Description\\n**Edge Cases in logic puzzles: ambiguous clue handling.**  \\nWhen clue wording is ambiguous (\"One house between\" vs. \"next to\" vs. \"left of\"), utilize both interpretations and select solutions with maximal clue satisfaction.\\n\\n### Example\\n\\n- For \"one house between X and Y\": Typically, abs(idx_X - idx_Y) == 2.\\n- Test both forward (X before Y) and reverse order; prefer solutions best matching majority clues.\\n\\n---\\n\\nGENERAL META-REASONING STRATEGIES\\n\\n---\\n\\n## Memory Item 8\\n**Count: 2**\\n\\n### Description\\n**High-level solving framework for Zebra/logic puzzles:**  \\n1. Tabular representation; assign direct clues.\\n2. Parse and link multi-attribute clues.\\n3. Track nearest-neighbor clues and order relations.\\n4. Systematically propagate assignments, always check uniqueness.\\n5. Validate each solution against every clue; if all satisfied or only ambiguous cases remain, proceed.\\n\\n### Example\\n\\n- For clues like \"A is the X, X is the Y\", assign all at once. For \"A is somewhere to the left of B\", restrict indices accordingly.\\n\\n---\\n\\n## Memory Item 9\\n**Count: 2**\\n\\n### Description\\n**Multi-layer elimination and backtracking for full clue validation.**  \\nIf a combination almost fits (e.g., one clue interpretation doesn\\'t match), use backtracking and test alternative orderings. Only accept solutions maximizing constraint satisfaction.\\n\\n### Example\\n\\n- Build and test multiple tables with slight variations in ambiguous clue interpretation, validate highest-consistency table.\\n\\n---\\n\\n## Memory Item 10\\n**Count: 2**\\n\\n### Description\\n**Definitive Example Table for a 4-house Zebra-type logic puzzle.**  \\nA solved example for cross-reference and testing new puzzles.\\n\\n### Example\\n\\n| House | Name   | Car           | Birthday | Hobby       |\\n|-------|--------|---------------|----------|-------------|\\n| 1     | Alice  | ford f150     | sept     | photography |\\n| 2     | Eric   | honda civic   | feb      | cooking     |\\n| 3     | Arnold | tesla model 3 | april    | painting    |\\n| 4     | Peter  | toyota camry  | jan      | gardening   |\\n\\n---'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    }
  ]
}