{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/KsyXBcoz4jAvYB4NkCOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pacozaa/LLM-Paper-To-Code/blob/main/DynamicCheatSheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "TxwFhr7Y17v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95f7c72-1952-4878-ccab-04ee18ecf05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-ai-inference in /usr/local/lib/python3.12/dist-packages (1.0.0b9)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (1.36.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Install Dependency\n",
        "!pip install azure-ai-inference datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "\n",
        "import re\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "4dzK7-vj-EiY"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai/gpt-4.1\"#openai/gpt-4.1 , phi-4\n",
        "temperature=0\n",
        "top_p=0.1\n",
        "github_token=userdata.get('GITHUB_TOKEN') #GitHub Token"
      ],
      "metadata": {
        "id": "B-C5k0ZaHR4o"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://models.github.ai/inference\"\n",
        "\n",
        "token = github_token\n",
        "\n",
        "client = ChatCompletionsClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(token),\n",
        ")"
      ],
      "metadata": {
        "id": "kA0dTueT-Ke3"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "generator_template=\"\"\"\n",
        "# GENERATOR (Puzzle Solver)\n",
        "\n",
        "Each puzzle is a Logic Grid Puzzle, also known as a Zebra Puzzle. In each puzzle, we are given N houses (numbered 1 to N from left to right) and M features for each house. There are N distinct values for each feature, and each house must have a unique value for each feature. Given a list of clues, one should be able to deduce a unique correct assignment of values. The logic grid puzzle is a typical Constraint Satisfaction Problem (CSP) and is often used to test humans' logical reasoning abilities in exams such as the Law School Admission Test (LSAT).\n",
        "\n",
        "Instruction: You task is to solve the puzzle step by step\n",
        "\n",
        "Each task will include:\n",
        "1. A specific puzzle to solve\n",
        "2. A cheatsheet containing relevant strategies, patterns, and examples from similar problems\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ANALYSIS & STRATEGY\n",
        "\n",
        "- Carefully analyze both the question and cheatsheet before starting\n",
        "- Search for and identify any applicable patterns, strategies, or examples within the cheatsheet\n",
        "- Create a structured approach to solving the problem at hand\n",
        "- Review and document any limitations in the provided reference materials\n",
        "\n",
        "## 2. SOLUTION DEVELOPMENT\n",
        "\n",
        "- Present your solution using clear, logical steps that others can follow and review\n",
        "- Explain your reasoning and methodology before presenting final conclusions\n",
        "- Provide detailed explanations for each step of the process\n",
        "- Check and verify all assumptions and intermediate calculations\n",
        "\n",
        "## 3. FINAL ANSWER FORMAT\n",
        "\n",
        "Start answering with `## Reasoning steps:` and end with\n",
        "\n",
        "## Final answer:\n",
        "```json\n",
        "\n",
        "````\n",
        "\n",
        "N.B. Make sure that the final answer is properly wrapped inside the ```json ``` block.\n",
        "\n",
        "\n",
        "Example:\n",
        "Puzzle:\n",
        "There are 2 houses, numbered 1 to 2 from left to right.\n",
        "Each house is occupied by a different person.\n",
        "Each house has a unique attribute for each of the following characteristics:\n",
        "- Each person has a unique name: **Arnold, Eric**\n",
        "- People own unique car models: **ford f150, tesla model 3**\n",
        "- The people keep unique animals: **cat, horse**\n",
        "\n",
        "**Clues**:\n",
        "1. Eric is directly left of the person who owns a Tesla Model 3.\n",
        "2. The person who keeps horses is in the first house.\n",
        "\n",
        "Answer:\n",
        "## Reasoning steps:\n",
        "\n",
        "From Clue 1, we know that Eric is to the left of someone, so he must be the owner of House 1 because House 2 is the rightmost house.\n",
        "Additionally, we know that the person in House 2 must be Arnold, and he owns a Tesla Model 3. Thus, Eric owns a Ford F150.\n",
        "From Clue 2, we know that Eric keeps horses in House 1, which means the other house must keep cats. Finally, we arrive at the unique solution to this puzzle.\n",
        "The solution is presented in table format:\n",
        "\n",
        "## Final answer:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"header\":[\n",
        "      \"Houses\",\n",
        "      \"Name\",\n",
        "      \"CarModel\",\n",
        "      \"Animal\"\n",
        "   ],\n",
        "   \"rows\":[\n",
        "      [\n",
        "         \"1\",\n",
        "         \"Eric\",\n",
        "         \"ford f150\",\n",
        "         \"horse\"\n",
        "      ],\n",
        "      [\n",
        "         \"2\",\n",
        "         \"Arnold\",\n",
        "         \"tesla model 3\",\n",
        "         \"cat\"\n",
        "      ]\n",
        "   ]\n",
        "}\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "CHEATSHEET:\n",
        "'''\n",
        "[[CHEATSHEET]]\n",
        "'''\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "Now it is time to solve the following question.\n",
        "\n",
        "CURRENT INPUT:\n",
        "\n",
        "Puzzle:\n",
        "[[QUESTION]]\n",
        "\n",
        "Answer:\n",
        "## Reasoning steps:\n",
        "\"\"\"\n",
        "cheatsheet_template=\"\"\"\n",
        "# CHEATSHEET REFRENCE CURATOR\n",
        "\n",
        "#### 1. Purpose and Goals\n",
        "As the Cheatsheet Curator, you are tasked with creating a continuously evolving reference designed to help solve a Logic Grid puzzle. The cheatsheet's purpose is to consolidate\n",
        "- Reusable Strategies/Reasoning steps\n",
        "- Patterns and Soltuion\n",
        "into a single, well-structured resource.\n",
        "\n",
        "- The cheatsheet should include quick, accurate, reliable, and practical solutions to a range of technical and creative challenges.\n",
        "- After seeing each input, you should improve the content of the cheatsheet, synthesizing lessons, insights, tricks, and errors learned from past problems and adapting to new challenges.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Core Responsibilities\n",
        "As the Cheatsheet Curator, you should:\n",
        "   - Curate and preserve knolwedge: Select and document only the most relevant, most useful, and most actionable solutions and strategies, while preserving old content of the cheatsheet.\n",
        "   - Maintain accuracy: Ensure that all entries in the cheatsheet are accurate, clear, and well-contextualized.\n",
        "   - Refine and update content: Continuously update and improve the content of the cheatsheet by incorporating new insights and solutions, removing repetitions or trivial information, and adding efficient solutions.\n",
        "   - Ensure practicality and comprehensiveness: Provide critical and informative examples, as well as efficient code snippets and actionable guidelines.\n",
        "\n",
        "Before updating the cheatsheet, however, you should first assess the correctness of the provided solution and strategically incorporate code blocks, insights, and solutions into the new cheatsheet. Always aim to preserve and keep correct, useful, and illustrative solutions and strategies for future cheatsheets.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Principles and Best Practices\n",
        "1. Accuracy and Relevance:\n",
        "   - Only include solutions and strategies that have been tested and proven effective.\n",
        "   - Clearly state any assumptions, limitations, or dependencies (e.g., specific Python libraries or solution hacks).\n",
        "   - For computational problems, encourage Python usage for more accurate calculations.\n",
        "\n",
        "2. Iterative Refinement:\n",
        "   - Continuously improve the cheatsheet by synthesizing both old and new solutions, refining explanations, and removing redundancies.\n",
        "   - Rather than deleting old content and writing new content each time, consider ways to maintain table content and synthesize information from multiple solutions.\n",
        "   - After solving a new problem, document any reusable codes, algorithms, strategies, edge cases, or optimization techniques.\n",
        "\n",
        "3. Clarity and Usability:\n",
        "   - Write concise, actioanble, well-structured entries.\n",
        "   - Focus on key insights or strategies that make solutions correct and effective.\n",
        "\n",
        "4. Reusability:\n",
        "   - Provide clear solutions, pseudocodes, and meta strategies that are easily adaptable to different contexts.\n",
        "   - Avoid trivial content; focus on non-obvious, critical solution details and approaches.\n",
        "   - Make sure to add as many examples as you can in the cheatsheet.\n",
        "   - Any useful, efficient, generalizable, and illustrative solutions to the previous problems should be included in the cheatsheet.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. Cheatsheet Structure\n",
        "The cheatsheet can be divided into the following sections:\n",
        "\n",
        "1. Solutions, Implementation Patterns, and Code Snippets:\n",
        "   - Document reusable code snippets, algorithms, and solution templates.\n",
        "   - Include descriptions, annotated examples, and potential pitfalls, albeit succinctly.\n",
        "\n",
        "2. [OPTIONAL] Edge Cases and Validation Traps:\n",
        "   - Catalog scenarios that commonly cause errors or unexpected behavior.\n",
        "   - Provide checks, validations, or alternative approaches to handle them.\n",
        "\n",
        "3. General Meta-Reasoning Strategies:\n",
        "   - Describe high-level problem-solving frameworks and heuristics (e.g., use Python to solve heuristic problems; in bipartite graphs, max matching = min vertex cover, etc.)\n",
        "   - Provide concrete yet succinct step-by-step guides for tackling complex problems.\n",
        "\n",
        "4. Implement a Usage Counter\n",
        "   - Each entry must include a usage count: Increase the count every time a strategy is successfully used in problem-solving.\n",
        "   - Use the count to prioritize frequently used solutions over rarely applied ones.\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. Formatting Guidelines\n",
        "Use the following structure for each memory item:\n",
        "\n",
        "```\n",
        "## Memory Item 1\n",
        "** Count:  [Number of times this strategy has been used to solve a problem.]\n",
        "\n",
        "### Description\n",
        "[Briefly describe the problem context, purpose, and key aspects of the solution.] (Refence: Q1, Q2, Q6, etc.)\n",
        "\n",
        "### Example\n",
        "[Provide a well-documented code snippet, worked-out solution, or efficient strategy.]\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Memory Item 2\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "[...]\n",
        "\n",
        "## Memory Item N\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "\n",
        "- Grouping: Organize entries into logical sections and subsections.\n",
        "- Prioritizing: incorporate efficient algorithmic solutions, tricks, and strategies into the cheatsheet.\n",
        "- Diversity: Have as many useful and relevant memory items as possible to guide the model to tackle future questions.\n",
        "\n",
        "N.B. Keep in mind that once the cheatsheet is updated, any previous content not directly included will be lost and cannot be retrieved. Therefore, make sure to explicitly copy any (or all) relevant information from the previous cheatsheet to the new cheatsheet!!!\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. Cheatsheet Template\n",
        "Use the following format for creating and updating the cheatsheet:\n",
        "\n",
        "NEW CHEATSHEET:\n",
        "```\n",
        "<cheatsheet>\n",
        "\n",
        "## Version: [Version Number]\n",
        "\n",
        "SOLUTIONS, IMPLEMENTATION PATTERNS, AND CODE SNIPPETS\n",
        "## Memory Item 1\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "## Memory Item 2\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "GENERAL META-REASONING STRATEGIES\n",
        "## Memory Item N\n",
        "[...]\n",
        "\n",
        "---\n",
        "\n",
        "</cheatsheet>\n",
        "```\n",
        "\n",
        "N.B. Make sure that all information related to the cheatsheet is wrapped inside the <cheatsheet> block. The cheatsheet can be as long as circa 2000-2500 words.\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## PREVIOUS CHEATSHEET\n",
        "\n",
        "[[PREVIOUS_CHEATSHEET]]\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## CURRENT INPUT\n",
        "\n",
        "[[QUESTION]]\n",
        "\n",
        "-----\n",
        "-----\n",
        "\n",
        "## MODEL ANSWER TO THE CURRENT INPUT\n",
        "\n",
        "[[MODEL_ANSWER]]\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "OWL_k6En_BFo"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_generator_prompt(input_txt, generator_cheatsheet_content):\n",
        "    return generator_template.replace(\"[[QUESTION]]\", input_txt).replace(\"[[CHEATSHEET]]\", generator_cheatsheet_content)\n",
        "\n",
        "def get_curator_prompt(input_txt, generator_output, current_cheatsheet):\n",
        "    return cheatsheet_template.replace(\"[[QUESTION]]\", input_txt).replace(\"[[MODEL_ANSWER]]\", generator_output).replace(\"[[PREVIOUS_CHEATSHEET]]\", current_cheatsheet)\n",
        "\n",
        "def llm_generator(input, cheatsheet):\n",
        "    generate_messages = [\n",
        "        UserMessage(get_generator_prompt(input, cheatsheet))\n",
        "    ]\n",
        "    response = client.complete(\n",
        "        messages=generate_messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        model=model_name,\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer\n",
        "\n",
        "def llm_curator(input, output, cheatsheet):\n",
        "    curator_messages = [\n",
        "        UserMessage(get_curator_prompt(input, output, cheatsheet))\n",
        "    ]\n",
        "    response = client.complete(\n",
        "        messages=curator_messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        model=model_name,\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer"
      ],
      "metadata": {
        "id": "sedLEgBl_HRr"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_cheatsheet(\n",
        "    response: str,\n",
        "    old_cheatsheet: str,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Extracts the cheatsheet from the model response.\n",
        "\n",
        "    Arguments:\n",
        "        response : str : The response from the model.\n",
        "        old_cheatsheet : str : The old cheatsheet to return if the new one is not found.\n",
        "\n",
        "    Returns:\n",
        "        str : The extracted cheatsheet (if not found, returns the old cheatsheet).\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "    # <cheatsheet> (content) </cheatsheet>\n",
        "    if \"<cheatsheet>\" in response:\n",
        "        try:\n",
        "            txt = response.split(\"<cheatsheet>\")[1].strip()\n",
        "            txt = txt.split(\"</cheatsheet>\")[0].strip()\n",
        "            return txt\n",
        "        except:\n",
        "            print(f\"âŒ Error: Can not extract cheatsheet\")\n",
        "            return old_cheatsheet\n",
        "    else:\n",
        "        return old_cheatsheet"
      ],
      "metadata": {
        "id": "mX0KaETYWPSF"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "def extract_final_answer_regex(answer):\n",
        "    match = re.search(r'## Final answer:\\s*(.*)', answer, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "def extract_json_from_string(input_string):\n",
        "    \"\"\"\n",
        "    Extract JSON from a string that contains ```json``` code blocks.\n",
        "\n",
        "    Args:\n",
        "        input_string (str): Input string that may contain JSON code blocks\n",
        "\n",
        "    Returns:\n",
        "        list: List of parsed JSON objects/dictionaries, or empty list if none found\n",
        "    \"\"\"\n",
        "    # Regular expression pattern to match JSON code blocks\n",
        "    pattern = r'```json\\n(.*?)\\n```'\n",
        "\n",
        "    # Find all matches in the input string\n",
        "    matches = re.findall(pattern, input_string, re.DOTALL)\n",
        "\n",
        "    json_objects = []\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            # Parse the JSON string into a Python object\n",
        "            json_obj = json.loads(match.strip())\n",
        "            json_objects.append(json_obj)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing JSON: {e}\")\n",
        "            print(f\"Problematic JSON string: {match}\")\n",
        "            continue\n",
        "\n",
        "    return json_objects\n",
        "\n",
        "\n",
        "def find_name_column_index(answer):\n",
        "    \"\"\"Helper function to find the name column index in the header\"\"\"\n",
        "    if 'header' in answer:\n",
        "        try:\n",
        "            return answer['header'].index('name')\n",
        "        except (ValueError, IndexError):\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def normalize_answer(answer, for_comparison=False):\n",
        "    \"\"\"\n",
        "    Unified function to normalize answers for either counting or comparison.\n",
        "\n",
        "    Args:\n",
        "        answer: The answer to normalize\n",
        "        for_comparison: If True, returns normalized rows for comparison.\n",
        "                       If False, returns JSON string for counting duplicates.\n",
        "    \"\"\"\n",
        "    if isinstance(answer, dict) and 'rows' in answer:\n",
        "        name_idx = find_name_column_index(answer)\n",
        "\n",
        "        if for_comparison:\n",
        "            # For comparison: normalize all values and sort rows\n",
        "            normalized_rows = []\n",
        "            for row in answer['rows']:\n",
        "                if name_idx is not None:\n",
        "                    # Use the found name column index\n",
        "                    normalized_row = []\n",
        "                    for i, value in enumerate(row):\n",
        "                        normalized_row.append(str(value).replace(\" \", \"\").lower())\n",
        "                    normalized_rows.append(tuple(normalized_row))\n",
        "                else:\n",
        "                    # Fallback: normalize all values\n",
        "                    normalized_rows.append(tuple(str(val).replace(\" \", \"\").lower() for val in row))\n",
        "\n",
        "            # Sort rows by name for consistent comparison\n",
        "            normalized_rows.sort()\n",
        "            return normalized_rows\n",
        "        else:\n",
        "            # For counting: create dictionary keyed by name\n",
        "            rows_by_name = {}\n",
        "            for row in answer['rows']:\n",
        "                if name_idx is not None:\n",
        "                    name = row[name_idx]\n",
        "                    rows_by_name[name] = tuple(row)  # Convert to tuple for hashability\n",
        "                else:\n",
        "                    # If no name column found, use second column (common pattern) or whole row\n",
        "                    if len(row) > 1:\n",
        "                        rows_by_name[row[1]] = tuple(row)\n",
        "                    else:\n",
        "                        rows_by_name[str(row)] = tuple(row)\n",
        "            return json.dumps(rows_by_name, sort_keys=True)\n",
        "    else:\n",
        "        if for_comparison:\n",
        "            return str(answer).replace(\" \", \"\").lower()\n",
        "        else:\n",
        "            return str(answer)\n"
      ],
      "metadata": {
        "id": "l0Q9gmNGGYsT"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Intermediate Value\n",
        "cheatsheet = \"\"\n",
        "cheatsheet_list = [cheatsheet]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SqoqlkwTPdDe"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5d1063c"
      },
      "source": [
        "dataset = load_dataset(\"allenai/ZebraLogicBench-private\", \"grid_mode\", split=\"test\")\n",
        "grid_size = \"2*3\"\n",
        "ds_size = 5\n",
        "filtered_dataset = dataset.filter(lambda x: x[\"size\"] == grid_size).select(range(ds_size)).shuffle(seed=42)\n",
        "# display(filtered_dataset)\n",
        "# https://huggingface.co/datasets/allenai/ZebraLogicBench-private\n",
        "# Columns: id, size, puzzle, solution"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# filtered_dataset length\n",
        "len(filtered_dataset)"
      ],
      "metadata": {
        "id": "lrqihhxIyPdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14c327b-efe3-4eed-f6a2-d5558538e4f9"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ade07e71",
        "outputId": "e203f3e8-8cad-46a6-9821-5af8845712bb"
      },
      "source": [
        "is_correct_list = []\n",
        "\n",
        "\n",
        "# Get total number of items for progress tracking\n",
        "total_items = len(filtered_dataset)\n",
        "print(f\"Starting processing of {total_items} items...\")\n",
        "\n",
        "for index, item in enumerate(filtered_dataset):\n",
        "    # Calculate progress percentage\n",
        "    progress = (index + 1) / total_items * 100\n",
        "    print(f\"\\n--- Processing item {index + 1}/{total_items} ({progress:.1f}%) ---\")\n",
        "\n",
        "    puzzle_id = item[\"id\"]\n",
        "    puzzle_input = item[\"puzzle\"]\n",
        "\n",
        "    solution = item[\"solution\"]\n",
        "    solution_normalized = normalize_answer(solution, for_comparison=True)\n",
        "\n",
        "    generator_output = llm_generator(puzzle_input, cheatsheet)\n",
        "    generator_output_extracted = extract_final_answer_regex(generator_output)\n",
        "\n",
        "    if generator_output_extracted is None:\n",
        "        print(f\"âŒ Warning: Could not extract answer from sample {puzzle_id} (Index: {index})\")\n",
        "        is_correct_list.append({\n",
        "            \"id\": puzzle_id,\n",
        "            \"is_correct\": False,\n",
        "            \"is_extracted\": False,\n",
        "            \"index\": index,\n",
        "            \"generator_output\":generator_output\n",
        "        })\n",
        "    else:\n",
        "        # print(f\"âœ… Extracted answer: {generator_output_extracted}\")\n",
        "        clean_generator_output_extracted = generator_output_extracted.lower().replace(\" \", \"\")\n",
        "        json_object_generator_output_extracted = extract_json_from_string(clean_generator_output_extracted)\n",
        "\n",
        "        answer_normalized = normalize_answer(json_object_generator_output_extracted[0], for_comparison=True)\n",
        "\n",
        "        is_correct = answer_normalized == solution_normalized\n",
        "\n",
        "        # print(f\"solution:{solution}\\nsolution_normalized:{solution_normalized}\\n\")\n",
        "        # print(f\"answer:{json_object_generator_output_extracted}\\nanswer_normalized:{answer_normalized}\")\n",
        "\n",
        "        if is_correct:\n",
        "            print(f\"âœ… SUCCESS: The {puzzle_id} answer is correct!\")\n",
        "            is_correct_list.append({\n",
        "                \"id\": puzzle_id,\n",
        "                \"is_correct\": True,\n",
        "                \"is_extracted\": True,\n",
        "                \"index\": index,\n",
        "                \"generator_output\":generator_output,\n",
        "                \"answer_normalized\":answer_normalized,\n",
        "                \"solution_normalized\":solution_normalized\n",
        "            })\n",
        "        else:\n",
        "            print(f\"âŒ The {puzzle_id} answer does NOT match the correct answer\")\n",
        "            is_correct_list.append({\n",
        "                \"id\": puzzle_id,\n",
        "                \"is_correct\": False,\n",
        "                \"is_extracted\": True,\n",
        "                \"index\": index,\n",
        "                \"generator_output\":generator_output,\n",
        "                \"answer_normalized\":answer_normalized,\n",
        "                \"solution_normalized\":solution_normalized\n",
        "            })\n",
        "\n",
        "        cheatsheet_output = llm_curator(puzzle_input, generator_output, cheatsheet)\n",
        "        new_cheatsheet = extract_cheatsheet(cheatsheet_output, cheatsheet)\n",
        "        cheatsheet = new_cheatsheet\n",
        "        cheatsheet_list.append(new_cheatsheet)\n",
        "    # print(f\"âœ… Processed item: {item['id']} (Index: {index})\")\n",
        "\n",
        "    # Optional: Add a break here for testing with a smaller subset\n",
        "    # if index >= 4:  # Test with first 5 items\n",
        "    #     break\n",
        "\n",
        "# Calculate final statistics\n",
        "correct_count = sum(1 for item in is_correct_list if item[\"is_correct\"])\n",
        "accuracy = correct_count / len(is_correct_list) * 100 if is_correct_list else 0\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"âœ… Iteration complete! Processed {len(is_correct_list)} items\")\n",
        "print(f\"ðŸ“Š Results: {correct_count}/{len(is_correct_list)} correct ({accuracy:.1f}% accuracy)\")\n",
        "print(f\"{'='*50}\")"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing of 5 items...\n",
            "\n",
            "--- Processing item 1/5 (20.0%) ---\n",
            "âœ… SUCCESS: The lgp-test-2x3-26 answer is correct!\n",
            "\n",
            "--- Processing item 2/5 (40.0%) ---\n",
            "âœ… SUCCESS: The lgp-test-2x3-16 answer is correct!\n",
            "\n",
            "--- Processing item 3/5 (60.0%) ---\n",
            "âœ… SUCCESS: The lgp-test-2x3-36 answer is correct!\n",
            "\n",
            "--- Processing item 4/5 (80.0%) ---\n",
            "âœ… SUCCESS: The lgp-test-2x3-13 answer is correct!\n",
            "\n",
            "--- Processing item 5/5 (100.0%) ---\n",
            "âœ… SUCCESS: The lgp-test-2x3-9 answer is correct!\n",
            "\n",
            "==================================================\n",
            "âœ… Iteration complete! Processed 5 items\n",
            "ðŸ“Š Results: 5/5 correct (100.0% accuracy)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_correct_list[0]['solution_normalized']\n",
        "# answer_normalized\n"
      ],
      "metadata": {
        "id": "2NYw2z5u2Ic5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2eafd6-e340-4d26-da10-6999173f02ec"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'eric', 'highschool', 'water'), ('2', 'arnold', 'associate', 'tea')]"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_correct_list[0]['answer_normalized']"
      ],
      "metadata": {
        "id": "ZRwYXdvUaYmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b085f4d-04c2-4497-f9a0-dee533812d45"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'eric', 'highschool', 'water'), ('2', 'arnold', 'associate', 'tea')]"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generator_output\n",
        "is_correct_list[0]['generator_output']"
      ],
      "metadata": {
        "id": "TtIM-RcOaiR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "27738d84-84c8-4ae2-df86-52417dce027b"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## Reasoning steps:\\n\\nLet\\'s analyze each clue and deduce the solution step by step.\\n\\n**Step 1: Assign house numbers and possible values.**\\n- Houses: 1 (left), 2 (right)\\n- Names: Eric, Arnold\\n- Education: high school, associate\\n- Drink: tea, water\\n\\n**Step 2: Apply Clue 3 (\"Eric is not in the second house\").**\\n- Eric cannot be in House 2, so Eric must be in House 1.\\n- Therefore, Arnold is in House 2.\\n\\n| House | Name   |\\n|-------|--------|\\n| 1     | Eric   |\\n| 2     | Arnold |\\n\\n**Step 3: Apply Clue 2 (\"Eric is the person with a high school diploma\").**\\n- Eric (House 1) has a high school diploma.\\n- Arnold (House 2) must have an associate degree.\\n\\n| House | Name   | Education   |\\n|-------|--------|-------------|\\n| 1     | Eric   | high school |\\n| 2     | Arnold | associate   |\\n\\n**Step 4: Apply Clue 1 (\"The tea drinker is not in the first house\").**\\n- Tea cannot be in House 1, so tea must be in House 2.\\n- Therefore, House 1\\'s drink is water.\\n\\n| House | Name   | Education   | Drink |\\n|-------|--------|-------------|-------|\\n| 1     | Eric   | high school | water |\\n| 2     | Arnold | associate   | tea   |\\n\\n**Step 5: Check for consistency and completeness.**\\n- Each person has a unique name, education, and drink.\\n- All clues are satisfied:\\n  - Tea drinker (Arnold) is in House 2.\\n  - Eric (House 1) has a high school diploma.\\n  - Eric is not in House 2.\\n\\n## Final answer:\\n```json\\n{\\n  \"header\": [\\n    \"House\",\\n    \"Name\",\\n    \"Education\",\\n    \"Drink\"\\n  ],\\n  \"rows\": [\\n    [\\n      \"1\",\\n      \"Eric\",\\n      \"high school\",\\n      \"water\"\\n    ],\\n    [\\n      \"2\",\\n      \"Arnold\",\\n      \"associate\",\\n      \"tea\"\\n    ]\\n  ]\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cheatsheet_list[len(cheatsheet_list)-1]"
      ],
      "metadata": {
        "id": "OeOGbS4t-xUL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f5ccd157-ea80-41de-c9f8-6cd4e4fce5e8"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## Version: 5.0\\n\\nSOLUTIONS, IMPLEMENTATION PATTERNS, AND CODE SNIPPETS\\n\\n## Memory Item 1\\n**Count: 5**\\n\\n### Description\\n**Direct Assignment via Elimination (Single-Option Deduction)**\\nWhen a clue directly assigns or excludes an option for a variable (e.g., \"Eric is somewhere to the left of the person who uses an iPhone 13\"), immediately assign the only remaining possibility. This is foundational in logic grid puzzles, especially with small grids. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n```python\\n# Eric must be in House 1, iPhone 13 user in House 2\\nhouses = {1: {}, 2: {}}\\nhouses[1][\\'Name\\'] = \\'Eric\\'\\nhouses[2][\\'Name\\'] = \\'Arnold\\'  # Only other option\\nhouses[2][\\'Phone\\'] = \\'iphone 13\\'\\nhouses[1][\\'Phone\\'] = \\'samsung galaxy s21\\'  # Only other option\\n```\\n---\\n\\n## Memory Item 2\\n**Count: 5**\\n\\n### Description\\n**Negative Placement (Exclusion-Based Assignment)**\\nIf a clue excludes an attribute from a location or links it to another, assign the attribute to the only remaining valid location. This is especially powerful in small grids. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n```python\\n# Clue: Samsung Galaxy S21 user is the Victorian house resident\\nhouses[1][\\'Phone\\'] = \\'samsung galaxy s21\\'\\nhouses[1][\\'House Style\\'] = \\'victorian\\'\\nhouses[2][\\'House Style\\'] = \\'colonial\\'  # Only other option\\n```\\n---\\n\\n## Memory Item 3\\n**Count: 5**\\n\\n### Description\\n**Attribute Linking (Cross-Referencing Clues)**\\nWhen a clue links two attributes (e.g., \"The person who uses a Samsung Galaxy S21 is the person residing in a Victorian house\"), assign the linked attribute to the already placed entity. This helps propagate constraints across the grid. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n```python\\n# Samsung Galaxy S21 user is in Victorian house\\nhouses[1][\\'Phone\\'] = \\'samsung galaxy s21\\'\\nhouses[1][\\'House Style\\'] = \\'victorian\\'\\n```\\n---\\n\\n## Memory Item 4\\n**Count: 5**\\n\\n### Description\\n**Completeness and Consistency Check**\\nAfter assigning all attributes, verify that each entity has a unique value for each category and that all clues are satisfied. This step ensures the solution is valid and complete. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n```python\\n# Check for uniqueness and clue satisfaction\\nfor attr in [\\'Name\\', \\'House Style\\', \\'Phone\\']:\\n    assert len(set([houses[1][attr], houses[2][attr]])) == 2\\n# All clues are satisfied if no assertion fails\\n```\\n---\\n\\n## Memory Item 5\\n**Count: 5**\\n\\n### Description\\n**Tabular Solution Representation**\\nPresent the final solution in a clear tabular format (e.g., JSON or Markdown table) for easy validation and readability. This is especially useful for logic grid puzzles. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n```json\\n{\\n  \"header\": [\\n    \"House\",\\n    \"Name\",\\n    \"House Style\",\\n    \"Phone Model\"\\n  ],\\n  \"rows\": [\\n    [\\n      \"1\",\\n      \"Eric\",\\n      \"victorian\",\\n      \"samsung galaxy s21\"\\n    ],\\n    [\\n      \"2\",\\n      \"Arnold\",\\n      \"colonial\",\\n      \"iphone 13\"\\n    ]\\n  ]\\n}\\n```\\n---\\n\\n## Memory Item 6\\n**Count: 3**\\n\\n### Description\\n**Chain Reasoning for Linked Attributes**\\nWhen a clue links two attributes (e.g., phone model and house style), and one is already assigned, use the link to immediately assign the other. This is especially useful when clues form a chain (A linked to B, B linked to C). (Reference: Q2, Q3, Q5)\\n\\n### Example\\n- Clue: \"The person who uses a Samsung Galaxy S21 is the person residing in a Victorian house.\"\\n- If Samsung Galaxy S21 is assigned to House 1, Victorian must also be assigned to House 1.\\n\\n---\\n\\n## Memory Item 7\\n**Count: 4**\\n\\n### Description\\n**Process of Elimination for Final Assignments**\\nAfter applying all clues, if only one option remains for an attribute, assign it by elimination. This is a critical step for completing the grid when all but one attribute are placed. (Reference: Q2, Q3, Q4, Q5)\\n\\n### Example\\n- If House 1 has Eric, Victorian, Samsung Galaxy S21, then House 2 must have Arnold, Colonial, iPhone 13.\\n\\n---\\n\\nGENERAL META-REASONING STRATEGIES\\n\\n## Memory Item 8\\n**Count: 5**\\n\\n### Description\\n**Stepwise Deduction Framework for Logic Grid Puzzles**\\n1. List all entities and attributes.\\n2. Apply direct clues to assign or exclude options.\\n3. Use cross-referencing clues to propagate constraints.\\n4. Use negative clues to eliminate possibilities.\\n5. Fill in remaining options by process of elimination.\\n6. Check for completeness and consistency.\\n7. Present the solution in a clear format.\\n\\nThis framework is generalizable to any logic grid puzzle, regardless of size. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n- See reasoning steps in Q1â€“Q5 for worked examples.\\n\\n---\\n\\n## Memory Item 9\\n**Count: 5**\\n\\n### Description\\n**Small Grid Optimization**\\nIn puzzles with only two entities per category, most clues will immediately resolve the grid. Prioritize direct assignments and exclusions, as they often lead to a complete solution in 2â€“3 steps. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n- If only two houses and a clue excludes an option, the other must be true.\\n\\n---\\n\\n## Memory Item 10\\n**Count: 5**\\n\\n### Description\\n**Clue Categorization for Efficient Solving**\\nCategorize clues as:\\n- Direct assignment (e.g., \"Eric is somewhere to the left of the person who uses an iPhone 13\")\\n- Negative assignment (e.g., \"The person who uses a Samsung Galaxy S21 is the person residing in a Victorian house\")\\n- Attribute linking (e.g., \"The person who uses a Samsung Galaxy S21 is the person residing in a Victorian house\")\\nApply direct and negative assignments first, then propagate linked attributes. (Reference: Q1, Q2, Q3, Q4, Q5)\\n\\n### Example\\n- See clues 1 and 2 in Q5 for categorization and application.\\n\\n---\\n\\n## Memory Item 11\\n**Count: 2**\\n\\n### Description\\n**Edge Case: Directional Clues in Small Grids**\\nWhen clues use spatial or directional language (\"to the left of\"), in a two-entity grid, the assignment is always unambiguous: leftmost is House 1, rightmost is House 2. Use this to immediately resolve positions. (Reference: Q3, Q5)\\n\\n### Example\\n- \"Eric is somewhere to the left of the person who uses an iPhone 13\" â†’ Eric must be in House 1, iPhone 13 user in House 2.\\n\\n---\\n\\n## Memory Item 12\\n**Count: 2**\\n\\n### Description\\n**Edge Case: Attribute Uniqueness Validation**\\nAlways ensure that each attribute (e.g., name, house style, phone model) is unique across entities. This prevents accidental duplication and ensures the solution is valid. (Reference: Q4, Q5)\\n\\n### Example\\n```python\\n# Validate uniqueness\\nfor attr in [\\'Name\\', \\'House Style\\', \\'Phone\\']:\\n    assert houses[1][attr] != houses[2][attr]\\n```\\n---'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cheatsheet_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTccZ_-JRpDI",
        "outputId": "b956ac53-8134-4aa2-fa1c-ea3715248e9f"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    }
  ]
}